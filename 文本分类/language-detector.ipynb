{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯完成语种检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似我们平时用的谷歌、百度翻译的语种检测..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这边有6种语言，拿来看看..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9066 entries, 0 to 9065\n",
      "Data columns (total 2 columns):\n",
      "0    9066 non-null object\n",
      "1    9066 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 141.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_train, split_test = train_test_split(data, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = split_train[0]\n",
    "y_train = split_train[1]\n",
    "X_test = split_test[0]\n",
    "y_test = split_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去掉文本中的噪声数据..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trump images are now more popular than cat gifs.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_noise(document):\n",
    "    noise_pattern = re.compile(\"|\".join([\"http\\S+\", \"\\@\\w+\", \"\\#\\w+\"]))\n",
    "    clean_text = re.sub(noise_pattern, \"\", document)\n",
    "    return clean_text.strip()\n",
    "\n",
    "remove_noise(\"Trump images are now more popular than cat gifs. @trump #trends http://www.trumptrends.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而对于文本中的词特征的抽取，我们依然使用词袋模型，可以选择n_gram，如：\n",
    "\n",
    "### 词袋模型 （默认为1_gram）\n",
    "\n",
    "我是中国人，我爱我的祖国 => 我 是 中国 人 ，我 爱 我 的 祖国 => (我:3 是:1 中国:1 人:1 爱:1)\n",
    "\n",
    "词表：4w个词\n",
    "\n",
    "以词袋表示该句子可能会出现如下形式：\n",
    "\n",
    "[0, 0, 0, ..., 0]\n",
    "[3, 1, 0, 1, ...]\n",
    "\n",
    "### 语言模型 n-gram（可以表达主宾颠倒所表达的不同意思）\n",
    "\n",
    "李雷喜欢韩梅梅\n",
    "\n",
    "[李雷，喜欢，韩梅梅，李雷 喜欢， 喜欢 韩梅梅]\n",
    "\n",
    "韩梅梅喜欢李雷\n",
    "\n",
    "[李雷，喜欢，韩梅梅，韩梅梅 喜欢， 喜欢 李雷]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 2),\n",
       "        preprocessor=<function remove_noise at 0x114181ae8>,\n",
       "        stop_words=None, strip_accents=None,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "            lowercase=True,\n",
    "            analyzer='char_wb',\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=1000,\n",
    "            preprocessor=remove_noise)\n",
    "vec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 34 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.transform(['10 der welt sind bei'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 词表\n",
    "# vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976621085134539"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以加大语料库，使得其准确率更高！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义为Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "class LanguageDetector():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classifier = MultinomialNB()\n",
    "        self.vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=1000,\n",
    "                                         preprocessor=self._remove_noise)\n",
    "        \n",
    "    def _remove_noise(self, document):\n",
    "        noise_pattern = re.compile(\"|\".join([\"http\\S+\", \"\\@\\w+\", \"\\#\\w+\"]))\n",
    "        clean_text = re.sub(noise_pattern, \"\", document)\n",
    "        return clean_text.strip()\n",
    "    \n",
    "    def features(self, X):\n",
    "        return self.vectorizer.transform(X)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.classifier.predict(self.features(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        return self.classifier.score(self.features(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_detector = LanguageDetector()\n",
    "language_detector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nl', 'nl', 'es', ..., 'es', 'es', 'en'], dtype='<U2')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_detector.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype='<U2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_detector.predict(['This is an English sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9801499779444199"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_detector.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
