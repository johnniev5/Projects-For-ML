{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/johnnie/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "import sys\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性概率统计（HMM问题1）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实就是要求联合概率：\n",
    "\n",
    "$$p(t_1 \\dots t_N, w_1 \\dots w_N)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动手之前我们先来看下词性统计应用HMM的贝叶斯公式：\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(t_1 \\dots t_N \\mid w_1 \\dots w_N) &= \\frac{p(t_1 \\dots t_N)p(w_1 \\dots w_N \\mid t_1 \\dots t_N)}{p(w_1 \\dots w_N)} \\\\\n",
    "&= \\frac{\\prod_{i=1}^Np(t_i \\mid t_{i-1})\\prod_{i=1}^Np(w_i \\mid t_i)}{\\prod_{i=1}^Np(w_i \\mid w_{i-1})} \\\\\n",
    "&=\\frac{\\prod_{i=1}^Np(t_i \\mid t_{i-1})p(w_i \\mid t_i)}{\\prod_{i=1}^Np(w_i \\mid w_{i-1})}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK需要对词添加开始和结束符号，用于标记开始和结束，用以下表示：\n",
    "\n",
    "(START, START), (END, END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags_words = []\n",
    "for sent in brown.tagged_sents():\n",
    "    brown_tags_words.append(('START', 'START'))\n",
    "    brown_tags_words.extend([(tag[:2], word) for (word, tag) in sent])\n",
    "    brown_tags_words.append(('END', 'END'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'START'),\n",
       " ('AT', 'The'),\n",
       " ('NP', 'Fulton'),\n",
       " ('NN', 'County'),\n",
       " ('JJ', 'Grand'),\n",
       " ('NN', 'Jury'),\n",
       " ('VB', 'said'),\n",
       " ('NR', 'Friday'),\n",
       " ('AT', 'an'),\n",
       " ('NN', 'investigation'),\n",
       " ('IN', 'of'),\n",
       " ('NP', \"Atlanta's\"),\n",
       " ('JJ', 'recent'),\n",
       " ('NN', 'primary'),\n",
       " ('NN', 'election'),\n",
       " ('VB', 'produced'),\n",
       " ('``', '``'),\n",
       " ('AT', 'no'),\n",
       " ('NN', 'evidence'),\n",
       " (\"''\", \"''\"),\n",
       " ('CS', 'that'),\n",
       " ('DT', 'any'),\n",
       " ('NN', 'irregularities'),\n",
       " ('VB', 'took'),\n",
       " ('NN', 'place'),\n",
       " ('.', '.'),\n",
       " ('END', 'END')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tags_words[:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计词库中相应tag下的词出现的概率，即为条件概率：\n",
    "\n",
    "$$p(w_i \\mid t_i) = \\frac{p(w_i, t_i)}{p(t_i)}$$\n",
    "\n",
    "可以使用count频率统计获得各自的概率！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计（词性，单词）出现的概率\n",
    "cfg_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "# 统计条件概率（单词 | 词性）的概率\n",
    "cpd_tagwords = nltk.ConditionalProbDist(cfg_tagwords, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an adjetive (JJ) being 'new' is 0.01472344917632025\n",
      "The probability of an verb (VB) being 'took' is 0.003668790248787141\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability of an adjetive (JJ) being 'new' is\", cpd_tagwords[\"JJ\"].prob(\"new\"))\n",
    "print(\"The probability of an verb (VB) being 'took' is\", cpd_tagwords[\"VB\"].prob('took'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再来看下词性转换的概率：\n",
    "\n",
    "$$p(t_i \\mid t_{i-1}) = \\frac{p(t_i, t_{i-1})}{p(t_{i-1})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brow_tags = [tag for (tag, word) in brown_tags_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计（词性t_i，词性t_{i-1}）的概率，bigram是实现前后词性连接成一组的方法\n",
    "cfd_tags = nltk.ConditionalFreqDist(nltk.bigrams(brow_tags))\n",
    "# 统计条件概率（词性t_i | 词性t_{i-1}）\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first one is 'DT', the probability of next one 'NN' is 0.5057722522030194\n",
      "The first one is 'VB', the probability of next one 'JJ' is 0.03443483365273389\n",
      "The first one is 'VB', the probability of next one 'NN' is 0.10970977711020183\n"
     ]
    }
   ],
   "source": [
    "print(\"The first one is 'DT', the probability of next one 'NN' is\", cpd_tags[\"DT\"].prob(\"NN\"))\n",
    "print(\"The first one is 'VB', the probability of next one 'JJ' is\", cpd_tags[\"VB\"].prob(\"JJ\"))\n",
    "print(\"The first one is 'VB', the probability of next one 'NN' is\", cpd_tags[\"VB\"].prob(\"NN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果说，有这么一句话“I love you”，对应的tag，“PP VB PP”，看看它们的联合概率是多少..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the tag sequence 'START PP VB PP END' for 'I love you' is: 7.038271983819719e-12\n"
     ]
    }
   ],
   "source": [
    "prob_tagsequence = cpd_tags[\"START\"].prob(\"PP\") * cpd_tagwords[\"PP\"].prob(\"I\") * \\\n",
    "    cpd_tags[\"PP\"].prob(\"VB\") * cpd_tagwords[\"VB\"].prob(\"love\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"PP\") * cpd_tagwords[\"PP\"].prob(\"you\") * \\\n",
    "    cpd_tags[\"VB\"].prob(\"END\")\n",
    "\n",
    "print( \"The probability of the tag sequence 'START PP VB PP END' for 'I love you' is:\", prob_tagsequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找最佳词性序列 （HMM问题2 - Viterbi实现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_tags = set(brow_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['I', 'love', 'you']\n",
    "sentlen = len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "backpointer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出各词性概率：\n",
      " {'AB': 0.0, ')-': 0.0, 'PN': 0.0, 'BE': 0.0, 'QL': 0.0, 'FW': 0.0, 'RN': 0.0, 'DT': 0.0, 'WP': 0.0, 'WR': 0.0, '(': 0.0, '.-': 0.0, 'AT': 0.0, 'AP': 0.0, 'MD': 0.0, 'WD': 0.0, 'HV': 0.0, '--': 0.0, 'NP': 1.7319067623793952e-06, 'EX': 0.0, 'END': 0.0, 'IN': 0.0, 'UH': 0.0, 'RB': 0.0, 'VB': 0.0, 'TO': 0.0, ':': 0.0, 'RP': 0.0, 'CS': 0.0, 'DO': 0.0, \"''\": 0.0, \"'\": 0.0, '``': 0.0, ')': 0.0, 'NN': 1.0580313619573935e-06, ',': 0.0, '*': 0.0, 'OD': 0.0, 'JJ': 0.0, ',-': 0.0, ':-': 0.0, 'WQ': 0.0, 'NI': 3.3324520848931064e-07, 'NR': 0.0, '.': 0.0, 'CD': 0.0, '(-': 0.0, 'CC': 0.0, '*-': 0.0, 'PP': 0.014930900689060006}\n",
      "\n",
      "\n",
      "输出词性序列：\n",
      " {'AB': 'START', ')-': 'START', 'PN': 'START', 'BE': 'START', 'QL': 'START', 'FW': 'START', 'RN': 'START', 'DT': 'START', 'WP': 'START', 'WR': 'START', '(': 'START', '.-': 'START', 'AT': 'START', 'AP': 'START', 'MD': 'START', 'WD': 'START', 'HV': 'START', '--': 'START', 'NP': 'START', 'EX': 'START', 'END': 'START', 'IN': 'START', 'UH': 'START', 'RB': 'START', 'VB': 'START', 'TO': 'START', ':': 'START', 'RP': 'START', 'CS': 'START', 'DO': 'START', \"''\": 'START', \"'\": 'START', '``': 'START', ')': 'START', 'NN': 'START', ',': 'START', '*': 'START', 'OD': 'START', 'JJ': 'START', ',-': 'START', ':-': 'START', 'WQ': 'START', 'NI': 'START', 'NR': 'START', '.': 'START', 'CD': 'START', '(-': 'START', 'CC': 'START', '*-': 'START', 'PP': 'START'}\n"
     ]
    }
   ],
   "source": [
    "first_viterbi = {}\n",
    "first_backpointer = {}\n",
    "for tag in distinct_tags:\n",
    "    if tag == 'START': continue\n",
    "    first_viterbi[tag] = cpd_tags['START'].prob(tag) * cpd_tagwords[tag].prob(sentence[0])\n",
    "    first_backpointer[tag] = 'START'\n",
    "        \n",
    "print('输出各词性概率：\\n', first_viterbi)\n",
    "print('\\n')\n",
    "print('输出词性序列：\\n', first_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi.append(first_viterbi)\n",
    "backpointer.append(first_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'I' current best two-tag sequence:  START PP\n"
     ]
    }
   ],
   "source": [
    "currbest = max(first_viterbi.keys(), key = lambda tag: first_viterbi[tag])\n",
    "print('Word', \"'\" + sentence[0] +\"'\", 'current best two-tag sequence: ', first_backpointer[currbest], currbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'love' current best two-tag sequence:  PP NN\n",
      "Word 'you' current best two-tag sequence:  VB PP\n"
     ]
    }
   ],
   "source": [
    "for wordindex in range(1, len(sentence)):\n",
    "    this_viterbi = {}\n",
    "    this_backpointer = {}\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    \n",
    "    for tag in distinct_tags:\n",
    "        if tag == 'START': continue\n",
    "        best_previous = max(prev_viterbi.keys(),\n",
    "                           key = lambda prevtag: \\\n",
    "            prev_viterbi[prevtag] * cpd_tags[prevtag].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex]))\n",
    "        this_viterbi[tag] = prev_viterbi[best_previous] * \\\n",
    "            cpd_tags[best_previous].prob(tag) * cpd_tagwords[tag].prob(sentence[wordindex])\n",
    "        this_backpointer[tag] = best_previous\n",
    "        \n",
    "    currbest = max(this_viterbi.keys(), key = lambda tag: this_viterbi[tag])\n",
    "    print('Word', \"'\" + sentence[wordindex] +\"'\", 'current best two-tag sequence: ', this_backpointer[currbest], currbest)\n",
    "    \n",
    "    viterbi.append(this_viterbi)\n",
    "    backpointer.append(this_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_viterbi = viterbi[-1]\n",
    "best_previous = max(prev_viterbi.keys(),\n",
    "                  key = lambda prevtag: prev_viterbi[prevtag] * cpd_tags[prevtag].prob('END'))\n",
    "prob_tagsequence = prev_viterbi[best_previous] * cpd_tags[best_previous].prob('END')\n",
    "best_tagsequence = ['END', best_previous]\n",
    "backpointer.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_best_tag = best_previous\n",
    "for bp in backpointer:\n",
    "    best_tagsequence.append(bp[current_best_tag])\n",
    "    current_best_tag = bp[current_best_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is:  I love you \n",
      "\n",
      "The best tag sequence is:  START PP VB PP END \n",
      "\n",
      "The probability of the best tag sequence is:  6.359015280071473e-13\n"
     ]
    }
   ],
   "source": [
    "best_tagsequence.reverse()\n",
    "print('The sentence is: ', end=' ')\n",
    "for w in sentence: print(w, end=' ')\n",
    "print('\\n')\n",
    "print('The best tag sequence is: ', end=' ')\n",
    "for t in best_tagsequence: print(t, end=' ')\n",
    "print('\\n')\n",
    "print('The probability of the best tag sequence is: ', prob_tagsequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import base, hmm, stats, utils\n",
    "from hmmlearn.hmm import GaussianHMM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
